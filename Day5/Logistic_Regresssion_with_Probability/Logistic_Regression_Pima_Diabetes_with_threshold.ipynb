{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "# calculate accuracy measures and confusion matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data lies in the following URL.\n",
    "#url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "\n",
    "pima_df = pd.read_csv(\"pima_diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_df.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets analysze the distribution of the various attributes\n",
    "pima_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at the target column which is 'class' to understand how the data is distributed amongst the various values\n",
    "\n",
    "pima_df['Class'].value_counts()\n",
    "# Most are not diabetic. The ratio is almost 1:2 in favor or class 0.  The model's ability to predict class 0 will \n",
    "# be better than predicting class 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot using sns\n",
    "\n",
    "#sns.pairplot(pima_df, hue='Class', diag_kind=\"kde\")\n",
    "sns.pairplot(pima_df, diag_kind=\"kde\", hue = \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for some the attributes are skewed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes which look normally distributed (plas, pres, skin, and mass).\n",
    "# Some of the attributes look like they may have an exponential distribution (preg, test, pedi, age).\n",
    "# Age should probably have a normal distribution, the constraints on the data collection may have skewed the distribution.\n",
    "\n",
    "# There is no obvious relationship between age and onset of diabetes.\n",
    "# There is no obvious relationship between pedi function and onset of diabetes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima_df.drop([\"Class\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pima_df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array = pima_df.values\n",
    "#X = array[:,0:7] # select all rows and first 8 columns which are the attributes\n",
    "#y = array[:,8]   # select all rows and the 9th column which is the classification \"Yes\", \"No\" for diabeties\n",
    "\n",
    "# instead, this could be done with DF also\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)\n",
    "#print(X_train.head())\n",
    "#print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit the model \n",
    "model = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the intercept and coefficients\n",
    "print(\"Intercept: \", model.intercept_)\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_y = model.predict_proba(X_test)\n",
    "\n",
    "#decisions = (model.predict_proba(X_test) >= 0.3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_prob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_df = pd.DataFrame(model.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.2\n",
    "y_pred_new = np.where(model.predict_proba(X_test)[:,1] >= THRESHOLD, 1, 0)\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred_new))\n",
    "print(metrics.confusion_matrix(y_test, y_pred_new))\n",
    "\n",
    "#pd.DataFrame(data=[accuracy_score(y_test, y_pred_new), recall_score(y_test, y_pred_new),\n",
    "#precision_score(y_test, y_pred_new), roc_auc_score(y_test, y_pred_new)], \n",
    "#index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "for i in threshold_list:\n",
    "    print ('\\n**** For Threshold = {} ****'.format(i))\n",
    "    y_pred_new = np.where(model.predict_proba(X_test)[:,1] >= i, 1, 0)\n",
    "    print(accuracy_score(y_test, y_pred_new))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred_new))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
