{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = pd.read_csv(\"credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.head(10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "credit_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(credit_df['checking_balance'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.info()  # many columns are of type object i.e. strings. These need to be converted to ordinal type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree in Python can take only numerical / categorical colums. It cannot take string / obeject types. \n",
    "# The following code loops through each column and checks if the column type is object then converts those columns\n",
    "# into categorical with each distinct value becoming a category or code.\n",
    "\n",
    "for feature in credit_df.columns: # Loop through all columns in the dataframe\n",
    "    if credit_df[feature].dtype == 'object': # Only apply for columns with categorical strings\n",
    "        credit_df[feature] = pd.Categorical(credit_df[feature]).codes # Replace strings with an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple methods exist\n",
    "# Label Encoder\n",
    "# or manually encoding\n",
    "#credit_df['checking_balance'] = credit_df['checking_balance'].replace({'< 0 DM':0, '1 - 200 DM':1, '> 200 DM':2, 'unknown':3 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train-test-split \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = credit_df.drop('default',axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = credit_df['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 0)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoking the decision tree classifier function. \n",
    "#Restricting the depth of the tree to 5 (no particular reason for selecting this)\n",
    "\n",
    "                                  \n",
    "dt_model = DecisionTreeClassifier( max_depth = 10, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "\n",
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing confusion matrix and accuracy\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training and testing score\n",
    "# Training Score\n",
    "print('Training score')\n",
    "print(dt_model.score(X_train,y_train))\n",
    "print('Test score')\n",
    "print(dt_model.score(X_test , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importance of features in the tree building ( The importance of a feature is computed as the \n",
    "#(normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
    "\n",
    "print (pd.DataFrame(dt_model.feature_importances_, columns = [\"Imp\"], index = X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphic representation of Decision Tree\n",
    "\n",
    "Start â€“ Anaconda prompt\n",
    "\n",
    "Visit: https://anaconda.org/conda-forge/python-graphviz\n",
    "\n",
    "To install this package with conda run one of the following:\n",
    "\n",
    "conda install python-graphviz \n",
    "\n",
    "conda install -c conda-forge python-graphviz \n",
    "\n",
    "conda install -c conda-forge/label/broken python-graphviz \n",
    "\n",
    "conda install -c conda-forge/label/cf201901 python-graphviz \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = ['No', 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "#import pydotplus as pydot\n",
    "from sklearn import tree\n",
    "from os import system\n",
    "\n",
    "Credit_Tree_File = open('e:\\credit_tree_1.dot','w')\n",
    "dot_data = tree.export_graphviz(dt_model, out_file=Credit_Tree_File, feature_names = list(X_train), class_names = list(class_label))\n",
    "#dot_data = tree.export_graphviz(dt_model, out_file=Credit_Tree_File, feature_names = list(X_train))\n",
    "Credit_Tree_File.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://webgraphviz.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can also copy the script inthe .dot file and paste it at http://webgraphviz.com/ to get tree view \n",
    "#or create a .png as below\n",
    "\n",
    "### system(\"dot -Tpng e:\\credit_tree_1.dot -o e:\\credit_tree_1.png\")\n",
    "### Image(\"e:\\credit_tree_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Hyper Parameters Tuning\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#making the instance\n",
    "model= DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 3\n",
    "\n",
    "# hyper parameters to build the model on\n",
    "params = {'max_depth': range(2, 20)}\n",
    "\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, cv=n_folds, return_train_score=True)\n",
    "#Learning\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model1.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "print(\"Best Score:\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune multiple papameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune multiple parameters\n",
    "#With Hyper Parameters Tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#making the instance\n",
    "model= DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "# hyper parameters to build the model on\n",
    "params = {'criterion':('gini','entropy'), \n",
    "          'max_depth': range(2, 10),\n",
    "         'min_samples_leaf': range(1, 8)}\n",
    "\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params)\n",
    "#Learning\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "print(\"Best Score:\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##                                      Regularising the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier( max_depth = 5, random_state=100)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print (pd.DataFrame(dt_model.feature_importances_, columns = [\"Imp\"], index = X_train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                             Ensemble Learning - Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bgcl = BaggingClassifier(base_estimator=dt_model, n_estimators=10, random_state=100)\n",
    "\n",
    "bgcl = bgcl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bgcl.predict(X_test)\n",
    "bgcl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcl = RandomForestClassifier(n_estimators = 5, random_state=100)\n",
    "rfcl = rfcl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = rfcl.predict(X_test)\n",
    "rfcl.score(X_test , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hyperparameter tuning of RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'n_estimators': range(50,150,5) ,\n",
    "    'max_depth': [5,10,15,20] \n",
    "    \n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv=5, \n",
    "                           n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
